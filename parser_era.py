# -*- coding: cp1251 -*-

from bs4 import BeautifulSoup
import requests

import os

import json

from datetime import datetime


were_added = ['Б0058906', 'Б0058905', 'Б0058902', 'Б0058884', 'Б0058883', 'Б0053391', 'Б0053392', 'Б0050576', 'Б0047784',
              'Б0041861', 'Б0026955', 'Б0026954', 'Б0035360', 'Б0055046', 'Б0054580', 'Б0055050', 'Б0055048', 'Б0055049',
              'Б0055047', 'Б0055044', 'Б0055042', 'Б0055040', 'Б0055045', 'Б0055043', 'Б0055041', 'Б0054582', 'Б0054581',
              'Б0052938', 'Б0052940', 'Б0052937', 'Б0052939', 'Б0054579', 'Б0047638', 'Б0036397', 'Б0036398', 'Б0047623',
              'Б0047615', 'Б0047619', 'Б0047616', 'Б0047620', 'Б0047624', 'Б0047628', 'Б0047632', 'Б0047630', 'Б0047629',
              'Б0047631', 'Б0047636', 'Б0047622', 'Б0047626', 'Б0047639', 'Б0047617', 'Б0047621', 'Б0047625', 'Б0047618',
              'Б0047637', 'Б0022452', 'Б0047635', 'Б0047634', 'Б0047633', 'Б0017326', 'Б0057717', 'Б0057716', 'Б0056747',
              'Б0057715', 'Б0056748', 'Б0041976', 'Б0047189', 'Б0041977', 'Б0041978', 'Б0047172', 'Б0041975', 'Б0047188',
              'Б0041973', 'Б0041974', 'Б0047174', 'Б0047177', 'Б0047176', 'Б0047179', 'Б0047175', 'Б0047173', 'Б0047178',
              'Б0053074', 'Б0051841', 'Б0051840', 'Б0052859', 'Б0054642', 'Б0052858', 'Б0054641', 'Б0043594', 'Б0043593',
              'Б0043592', 'Б0043591', 'Б0043590', 'Б0043589', 'Б0043587', 'Б0043586', 'Б0043585', 'Б0043576', 'Б0043575',
              'Б0043574', 'Б0052857', 'Б0043573', 'Б0054640', 'Б0052023', 'Б0052029', 'Б0052030', 'Б0052031', 'Б0052032',
              'Б0052021', 'Б0054639', 'Б0052022', 'Б0052024', 'Б0052025', 'Б0052026', 'Б0052027', 'Б0052028', 'Б0050955',
              'Б0043588', 'Б0043569', 'Б0050951', 'Б0054264', 'Б0054265', 'Б0054266', 'Б0054584', 'Б0054586', 'Б0049547',
              'Б0049548', 'Б0049545', 'Б0049546', 'Б0044394', 'Б0044389', 'Б0044396', 'Б0044397', 'Б0044399', 'Б0044404',
              'Б0044405', 'Б0051843', 'Б0044387', 'Б0044388', 'Б0044391', 'Б0051842', 'Б0044395', 'Б0044398', 'Б0044400',
              'Б0044390', 'Б0051845', 'Б0051844', 'Б0046678', 'Б0046676', 'Б0046675', 'Б0051846', 'Б0046677', 'Б0058867',
              'Б0058891', 'Б0058879', 'Б0058880', 'Б0058885', 'Б0058886', 'Б0058887', 'Б0058888', 'Б0050573', 'Б0058889',
              'Б0050572', 'Б0058890', 'Б0058892', 'Б0050553', 'Б0050585', 'Б0050584', 'Б0058895', 'Б0058896', 'Б0058899',
              'Б0058900', 'Б0050561', 'Б0050560', 'Б0058903', 'Б0058904', 'Б0058861', 'Б0050552', 'Б0058862', 'Б0058876',
              'Б0050578', 'Б0058864', 'Б0058865', 'Б0058866', 'Б0050575', 'Б0050574', 'Б0058868', 'Б0050577', 'Б0050579',
              'Б0058871', 'Б0058863', 'Б0058872', 'Б0058875', 'Б0050580', 'Б0050581', 'Б0050569', 'Б0050547', 'Б0050559',
              'Б0050538', 'Б0050586', 'Б0050563', 'Б0050549', 'Б0050582', 'Б0050541', 'Б0050583', 'Б0050555', 'Б0050554',
              'Б0050558', 'Б0050571', 'Б0050562', 'Б0050568', 'Б0050539', 'Б0050570', 'Б0050564', 'Б0050565', 'Б0050540',
              'Б0050542', 'Б0050544', 'Б0050548', 'Б0050588', 'Б0050589', 'Б0050546', 'Б0050587', 'Б0050550', 'Б0050567',
              'Б0050556', 'Б0050557', 'Б0050551', 'Б0050566', 'Б0056746', 'Б0058654', 'Б0051583', 'Б0051550', 'Б0056745',
              'Б0058253', 'Б0058663', 'Б0058672', 'Б0058667', 'Б0046472', 'Б0051558', 'Б0051630', 'Б0051631', 'Б0051609',
              'Б0051611', 'Б0051602', 'Б0051568', 'Б0051556', 'Б0051570', 'Б0051547', 'Б0046479', 'Б0046473', 'Б0046480',
              'Б0046471', 'Б0046475', 'Б0046476', 'Б0051546', 'Б0046470', 'Б0046478', 'Б0046474', 'Б0046477', 'Б0039056',
              'Б0047785', 'Б0039318', 'Б0047783', 'Б0039057', 'Б0039319', 'Б0051770', 'Б0051769', 'Б0032481',
              'Б0035359', 'Б0052249', 'Б0036411', 'Б0022451', 'Б0036420', 'Б0043658', 'Б0043659', 'Б0043657', 'Б0043655',
              'Б0043654', 'Б0052438', 'Б0029130']


files = [
    "c363.html", "c372.html", "c388.html", "c390.html", "c2070.html", "c2071.html", "c2072.html", "c2501.html",
    "c2524.html"
    ]

data = {}
data["products"] = []

for file in files:
    mistakes = []
    print("Категория началась, ", datetime.now().strftime("%H:%M:%S"))
    link = ''
    try:
        links = []
        with open(file, 'rb') as f:

            html = f.read()
            text = BeautifulSoup(html, "html.parser")

            divs_w_links = text.findAll("div", class_="media-body")
            for i in divs_w_links:
                link = i.find_next("div").find_next("a")
                if 'светодиод'.lower() in link.text.lower():
                    links.append(i.find_next("div").find_next("a")['href'])

        for link in links:
            context = {
                "Код товара": "",
                "Название": "",
                "Категория": ""
            }

            page = requests.get(link)
            full_text = BeautifulSoup(page.text, "html.parser")

            context['Код товара'] = full_text.find(name="small").text.split(" ")[2]
            if context['Код товара'] in were_added:
                continue

            features_and_values = str(full_text.find(id="itemProporties")).split("ETIM")[0]
            text = BeautifulSoup(features_and_values, features="html.parser")

            feature_titles = text.find_all("div", class_="col col-lg-4 col-md-6")
            features = []
            for feature in feature_titles:
                features.append(feature.text.strip())

            feature_values = text.find_all("div", class_="readmore_block")
            values = []
            for value in feature_values:
                values.append(value.text.strip())

            for i in range(len(features)):
                context.update({f"{features[i]}": values[i]})

            context['Название'] = full_text.find(name="title").text
            context['Описание'] = full_text.find(class_="readmore_block").text.replace("\n", "")
            context['Категория'] = "https://www.eraworld.ru/catalog/category/" + file.split(".html")[0][1:]

            data["products"].append(context)
            if not context['Код товара'] in os.listdir("result/eraworld/"):
                os.makedirs(f"result/eraworld/{context['Код товара']}", exist_ok=True)

                img_div = full_text.find("div", "gallery_preview")
                images = img_div.find_all(name="img")

                i = 1
                for image in images:
                    response = requests.get(image["data-rel"])
                    file_img = open(f"result/eraworld/{context['Код товара']}/{i}.jpg", 'bw')
                    for chunk in response.iter_content(4096):
                        file_img.write(chunk)

                    i += 1
    except:
        mistakes.append(link)

    print("Категория обработана, ", datetime.now().strftime("%H:%M:%S"), mistakes)

with open('result/eraworld/data.json', 'a', encoding="utf-8") as data_file:
    json.dump(data, data_file, ensure_ascii=False)
